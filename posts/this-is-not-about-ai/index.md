---
title: "This post is not about AI"
description: "Generative AI is often a flawed solution to very real problems. Observing current uses of AI may tell us more about our society than about AI itself."
date: "2026-01-15"
tags:
 - opinion
 - en
 - ai
layout: layouts/en_post.njk
---
# {{title}}

The most common use of LLMs is to look for information. You freak out because people are using a power-hungry bullshit generator instead of doing a search. Have you used Google lately? Have you managed to find actual results between the ads and the push for other Google products? Have you clicked on a link only to end up facing a cookie popup, followed by either a paywall or an ad-filled garbage page that was probably generated by AI anyway?

Of course people use LLMs. Google, and most of the websites it shows suck.

You're horrified to learn that “hundreds of millions of people [are] asking health and wellness questions each week” ([OpenAI, Jan 7 2026](https://openai.com/index/introducing-chatgpt-health/)).
Breaking news: OpenAI just released a new health product to help you connect your medical information directly to ChatGPT. Is this real? Are people really going to give their personal medical data to the biggest data thief of all time? Are they really asking ChatGPT instead of a doctor?

Well, have you tried to see a doctor recently? Did you get an appointment without waiting days, weeks, or even months? Were you treated well, or did you get the feeling your doctor learned everything about the human body but nothing about how to talk to a human being? How much did you pay?

Sure they’ll use LLMs for health questions. Healthcare is horrible[^1].

You can’t understand people getting attached to an LLM, seeing it as a friend or a lover. Don’t they know it’s just a machine? A program? A deterministic manipulation of ones and zeros?

A few years ago, I was volunteering for a suicide hotline. A free phone number anyone could call, anonymously, to talk to someone. People called for all sorts of reasons. They’d had a bad day, bad news, a bad fight. But mostly they called because they felt lonely. They needed someone to listen, someone to help them get through what they were living, and they didn’t have anyone they felt they could turn to.

During each call, the phone kept ringing. Other callers were trying to reach the line non-stop. It takes a certain amount of courage to call such a number, to decide it’s better to reach out to a stranger than to stay alone. It must feel awful to be met with a busy tone.

I could answer maybe one out of every three or four calls. What did the others do? What do they do now? Do they turn to ChatGPT? Is it helping them? Do they feel less lonely?

AI is full of problems, but it’s also damned good at showing us the problems we already had.

[^1]: And this is from a european perspective, I know we're far from having the worst healthcare system.
